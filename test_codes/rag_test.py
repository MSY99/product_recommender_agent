"""
â¡ï¸ Naive RAGì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ì½”ë“œì…ë‹ˆë‹¤.
"""

from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

persist_dir = "/workspace/data/chromaDB"
ENCODER = "dragonkue/BGE-m3-ko"

embedding_model = HuggingFaceEmbeddings(model_name=ENCODER)
vectorstore = Chroma(
    persist_directory=persist_dir,
    embedding_function=embedding_model,
)

retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

def rag_to_context(query: str) -> str:
    retrieved_docs = retriever.invoke(query)

    # ğŸ” None ì œê±°
    valid_docs = [doc for doc in retrieved_docs if doc.page_content]

    if not valid_docs:
        return "â— ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    result = "\n\n".join(
        f"Title: {doc.metadata.get('title', 'No Title')}\n"
        f"Category: {doc.metadata.get('category', 'N/A')}\n"
        f"{doc.page_content}"
        for doc in valid_docs
    )
    return result

if __name__ == "__main__":
    query = "ì†Œì…œ ë¯¸ë””ì–´ í”Œë«í¼ íšŒì‚¬ì—ì„œ IBM ì„œë²„ë¥¼ ë„ì…í•œ ì‚¬ë¡€ë¥¼ ì•Œë ¤ì¤˜."

    result = rag_to_context(query)
    print(result)
