import streamlit as st
import asyncio
import nest_asyncio
import os
import io
import platform
import shutil
import json

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from rfp_extracter import extract_text_from_pdf, extract_text_from_docx, convert_rfp_to_RAG

# Windows í™˜ê²½ ë¹„ë™ê¸° ì„¤ì •
if platform.system() == "Windows":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
nest_asyncio.apply()

# Streamlit ì „ì—­ event loop ìƒì„±
if "event_loop" not in st.session_state:
    loop = asyncio.new_event_loop()
    st.session_state.event_loop = loop
    asyncio.set_event_loop(loop)

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SAVE_FOLDER = os.path.join(BASE_DIR, "uploaded_pdfs")
os.makedirs(SAVE_FOLDER, exist_ok=True)

if "pdf_upload_key" not in st.session_state:
    st.session_state["pdf_upload_key"] = 0

# ëŒ€í™” ì„¸ì…˜ ì´ˆê¸°í™”
if "history" not in st.session_state:
    st.session_state.history = []

# GPT-4o ëª¨ë¸ ê³ ì •
MODEL_NAME = "gpt-4o"
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# GPT-4o Langchain ê°ì²´ ì¤€ë¹„
llm = ChatOpenAI(
    model=MODEL_NAME,
    temperature=0.1,
    max_tokens=16000,
    api_key=OPENAI_API_KEY
)

# PDF ì—…ë¡œë“œ ì‚¬ì´ë“œë°”
with st.sidebar:
    if st.button("ëŒ€í™” ì´ˆê¸°í™”", key="init_chat"):
        st.session_state.chat_history = []
        st.session_state["rag_term"] = ""
        if "uploaded_file_path" in st.session_state and st.session_state["uploaded_file_path"]:
            try:
                os.remove(st.session_state["uploaded_file_path"])
                st.success(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: `{os.path.basename(st.session_state['uploaded_file_path'])}`")
            except Exception as e:
                st.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
            st.session_state["uploaded_file_path"] = None

    st.subheader("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "PDF ë˜ëŠ” DOCX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=["pdf", "docx"],
        key="file_uploader"
    )

    if uploaded_file is not None:
        # íŒŒì¼ ì„ì‹œ ì €ì¥
        file_bytes = uploaded_file.read()
        tmp_path = os.path.join("/tmp", uploaded_file.name)
        with open(tmp_path, "wb") as f:
            f.write(file_bytes)
        st.session_state["uploaded_file_path"] = tmp_path
        st.success(f"ì—…ë¡œë“œ ì™„ë£Œ: `{uploaded_file.name}`")

        file_type = None
        if uploaded_file.name.lower().endswith(".pdf"):
            file_type = "pdf"
        elif uploaded_file.name.lower().endswith(".docx"):
            file_type = "docx"

        # íŒŒì¼ buffer
        file_buffer = io.BytesIO(file_bytes)
        file_buffer.seek(0)

        try:
            if file_type == "pdf":
                st.info("PDF íŒŒì¼ë¡œ ì¸ì‹ë¨. í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤...")
                txt_path = extract_text_from_pdf(file_buffer)      # ì„ì‹œ txt ê²½ë¡œ(str)
            elif file_type == "docx":
                st.info("DOCX íŒŒì¼ë¡œ ì¸ì‹ë¨. í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤...")
                txt_path = extract_text_from_docx(file_buffer)     # ì„ì‹œ txt ê²½ë¡œ(str)
            else:
                st.warning("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
                txt_path = None

            if txt_path:
                # (í™”ë©´ì— ë¯¸ë¦¬ë³´ê¸°ë¡œ ë„ìš°ëŠ” ìš©ë„)
                with open(txt_path, encoding="utf-8") as tf:
                    extracted_text = tf.read()
                st.success("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
                st.text_area(f"{file_type.upper()} í…ìŠ¤íŠ¸", extracted_text, height=300)
                
                # [ìˆ˜ì •] ì„ì‹œíŒŒì¼ ê²½ë¡œ(txt_path)ë¥¼ convert_rfp_to_RAGì— ë„˜ê²¨ì•¼ ì•ˆì „!
                rag_term = convert_rfp_to_RAG(txt_path)
                st.session_state["rag_term"] = rag_term
        except Exception as e:
            st.error(f"{file_type.upper()} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    else:
        st.session_state["uploaded_file_path"] = None
        st.info("PDF ë˜ëŠ” DOCX íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        st.session_state["rag_term"] = ""
    st.divider()

# ë©”ì¸ í˜ì´ì§€
st.title("ğŸ–¥ï¸ Agent Demo")
st.markdown("âœ¨ Ask questions to the GPT-4o agent about your PDF document.")

# ëŒ€í™” ê¸°ë¡ ì¶œë ¥ í•¨ìˆ˜
def print_message():
    for message in st.session_state.history:
        if message["role"] == "user":
            st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(message["content"])
        elif message["role"] == "assistant":
            st.chat_message("assistant", avatar="ğŸ¤–").markdown(message["content"])

print_message()

# ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜ (ë¹„ë™ê¸°)
async def process_query(query):
    try:
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œëœ í´ë”ê°€ ìˆìœ¼ë©´ ë‚´ìš© ê²°í•©í•˜ì—¬ contextë¡œ ì‚¬ìš©
        context = ""
        if "preprocessed_pdf_dir" in st.session_state:
            output_dir = st.session_state["preprocessed_pdf_dir"]
            txt_files = sorted(f for f in os.listdir(output_dir) if f.endswith(".txt"))
            for file in txt_files:
                with open(os.path.join(output_dir, file), encoding="utf-8") as f:
                    context += f.read() + "\n"
        else:
            context = ""

        prompt = f"""You are a helpful assistant. Answer the user's question based on the following context (if any).
        If there is no context, just answer as best as you can.
        ---
        Context:
        {context}
        ---
        Question: {query}
        Answer:"""

        resp = await llm.ainvoke([HumanMessage(content=prompt)])
        return resp.content
    except Exception as e:
        return f"âŒ Error: {e}"

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
user_query = st.chat_input("ğŸ’¬ Enter your question")
if user_query:
    st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(user_query)
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        with st.spinner("Generating answer..."):
            answer = st.session_state.event_loop.run_until_complete(process_query(user_query))
            st.markdown(answer)
    st.session_state.history.append({"role": "user", "content": user_query})
    st.session_state.history.append({"role": "assistant", "content": answer})
    st.rerun()

# ë¦¬ì…‹ ë²„íŠ¼(ì‚¬ì´ë“œë°”)
with st.sidebar:
    st.subheader("ğŸ”„ Actions")
    if st.button("Reset Conversation", use_container_width=True, type="primary"):
        st.session_state.history = []
        st.success("âœ… Conversation has been reset.")
        st.rerun()
